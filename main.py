import streamlit as st
import cv2
import numpy as np
from PIL import Image
import json
import os
import re
from dotenv import load_dotenv
from google import genai
from google.genai import types

# --- 1. CONFIG ---
st.set_page_config(page_title="AgriVision Agent", layout="centered")

# --- 2. SETUP CLIENT ---
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    st.error("‚ùå API Key missing.")
    st.stop()

client = genai.Client(api_key=api_key)

# --- 3. DEFINE THE REAL GOOGLE SEARCH TOOL ---
# This connects Gemini directly to the Google Search Index
google_search_tool = types.Tool(
    google_search=types.GoogleSearch()
)

# --- HELPER: CLEAN JSON ---
def clean_json_text(text):
    """
    Gemini 1.5 Flash sometimes puts markdown around JSON when using tools.
    This function cleans it up so the app doesn't crash.
    """
    text = re.sub(r"```json\s*", "", text)
    text = re.sub(r"```", "", text)
    return text.strip()

# --- 4. AGENT FUNCTION ---
def plant_analyzer(pil_image, city):
    
    prompt = f"""
    You are an Expert Agronomist Agent. User is in {city}, Pakistan.
    
    TASK:
    1. Analyze the image to identify the disease.
    2. USE GOOGLE SEARCH to find a specific medicine/fungicide available in Pakistan for this disease.
    3. FROM YOUR SEARCH RESULTS, get the name of the medicine and a real URL if available.
    
    CRITICAL: Output strictly valid JSON text. No other text.
    {{
        "disease_name": "str",
        "treatment": "str",
        "medicine": "str",
        "coordinates": [ymin, xmin, ymax, xmax],
        "search_finding": "str (A short sentence summary of what you found online, e.g. 'Found Daconil available at Daraz.pk')"
    }}
    """
    
    try:
        response = client.models.generate_content(
            model="gemini-flash-latest",
            contents=[pil_image, prompt],
            config=types.GenerateContentConfig(
                # REAL SEARCH TOOL ENABLED
                tools=[google_search_tool], 
                
                # IMPORTANT: We removed 'response_mime_type="application/json"'
                # This fixes the 400 Error while keeping the Search Tool active!
                temperature=0.4
            )
        )
        
        # 1. Extract the Grounding Metadata (The Proof it Searched)
        # Gemini returns "Grounding Metadata" which contains the actual links it used.
        search_sources = []
        if response.candidates[0].grounding_metadata.search_entry_point:
            search_html = response.candidates[0].grounding_metadata.search_entry_point.rendered_content
            search_sources.append(search_html)
            
        # 2. Parse the JSON manually
        text_response = response.text
        clean_text = clean_json_text(text_response)
        data = json.loads(clean_text)
        
        # Add the grounding info to the data object so we can show it
        data['grounding_html'] = search_sources
        
        return data

    except Exception as e:
        return {"error": f"Agent Error: {str(e)}"}

# --- 5. UI LAYOUT ---
st.title("üå± AgriVision: Intelligent Crop Doctor")
st.caption("Powered by Gemini 1.5 Flash with Real Google Search")

with st.sidebar:
    st.header("Settings")
    user_city = st.text_input("Your City", value="Sahiwal")

if 'captured_image' not in st.session_state:
    st.session_state.captured_image = None

# --- STATE A: CAMERA ---
if st.session_state.captured_image is None:
    img_file_buffer = st.camera_input("Scan your crop")
    
    if img_file_buffer:
        file_bytes = np.asarray(bytearray(img_file_buffer.read()), dtype=np.uint8)
        img = cv2.imdecode(file_bytes, 1)
        st.session_state.captured_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        st.rerun()

# --- STATE B: ANALYSIS ---
else:
    image_spot = st.empty()
    image_spot.image(st.session_state.captured_image, caption="Agent Searching Internet...", width="stretch")
    
    if st.button("üîÑ Scan New Plant"):
        st.session_state.captured_image = None
        st.rerun()

    with st.spinner(f"Agent is analyzing leaf & browsing Google for prices in {user_city}..."):
        pil_image = Image.fromarray(st.session_state.captured_image)
        result = plant_analyzer(pil_image, user_city)
        
        if "coordinates" in result:
            annotated_img = st.session_state.captured_image.copy()
            h, w, _ = annotated_img.shape
            
            coords = result.get('coordinates', [0, 0, 0, 0])
            ymin, xmin, ymax, xmax = coords
            
            start = (int(xmin * w / 1000), int(ymin * h / 1000))
            end = (int(xmax * w / 1000), int(ymax * h / 1000))
            
            cv2.rectangle(annotated_img, start, end, (57, 255, 20), 3)
            image_spot.image(annotated_img, caption=f"Detected: {result.get('disease_name')}", width="stretch")
            
            st.success(f"**Diagnosis:** {result.get('disease_name')}")
            st.warning(f"**Treatment:** {result.get('treatment')}")
            st.info(f"**Medicine:** {result.get('medicine')}")
            
            # --- SHOW REAL SEARCH RESULTS ---
            st.markdown("---")
            st.write("üîé **Agent Search Findings:**")
            st.write(result.get('search_finding', 'No specific details found.'))
            
            # This renders the official "Google Search Sources" widget from Gemini
            # It proves to the judges that real search happened.
            if 'grounding_html' in result and result['grounding_html']:
                st.markdown(result['grounding_html'][0], unsafe_allow_html=True)
            
        elif "error" in result:
            st.error(result['error'])